# llm_JFAG
Repositorio para implementar LLM 

#1.instalaci칩n 

como primer paso descargamos ollama desde su p치gina web [ollama](https://ollama.com/download/linux) de su p치gina web y esperamo ejecutamos el siguiente Colorad comando:

````bash
$ curl -fsSL https://ollama.com/install.sh | sh
````

#2.ejecutar el servidor 
ejecutar el servidor de api rest de ollama con el siguiente comando

````bash
$ ollama serve
````

#3.descargar un modelo 

en la p치gina de ollamab descarga un modelo [modelo](https://ollama.com/library) utilizando el siguiente comando:

````bash
$ ollama pull tinyllama
````


